import { useState, useRef, useCallback, useEffect } from 'react';
import {
  createSpeechRecognition,
  processVoiceCommand,
  processVoiceCommandWithConfidence,
  suggestCorrections
} from '../services/voiceAI';
import { buildProductIndex } from '../services/hybridSearch';
import { useStore } from './useStore';

// Thá»i gian chá» trÆ°á»›c khi xá»­ lÃ½ lá»‡nh (ms)
// Cho phÃ©p ngÆ°á»i dÃ¹ng ngáº­p ngá»«ng vÃ  tiáº¿p tá»¥c nÃ³i
const COMMAND_DELAY_MS = 1700;

export const useVoice = () => {
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [alternatives, setAlternatives] = useState([]);
  const [result, setResult] = useState(null);
  const [isSupported, setIsSupported] = useState(true);
  const [suggestions, setSuggestions] = useState([]);
  const [transcriptHistory, setTranscriptHistory] = useState([]);
  const [isWaitingForMore, setIsWaitingForMore] = useState(false); // Äang chá» ngÆ°á»i dÃ¹ng nÃ³i thÃªm
  const [tfidfIndex, setTfidfIndex] = useState(null); // TF-IDF index for better product matching

  const recognitionRef = useRef(null);
  const callbackRef = useRef(null);
  const processTimeoutRef = useRef(null); // Timeout Ä‘á»ƒ debounce
  const accumulatedTranscriptRef = useRef(''); // TÃ­ch lÅ©y transcript qua nhiá»u láº§n nÃ³i
  const accumulatedConfidenceRef = useRef(0);
  const accumulatedAlternativesRef = useRef([]);
  const { products, customers, showNotification } = useStore();

  // Build TF-IDF index when products change
  useEffect(() => {
    if (products && products.length > 0) {
      console.log('ğŸ”„ Building TF-IDF index for voice search...');
      try {
        const index = buildProductIndex(products);
        setTfidfIndex(index);
        console.log('âœ… TF-IDF index ready for voice commands');
      } catch (error) {
        console.error('âŒ Failed to build TF-IDF index:', error);
        setTfidfIndex(null);
      }
    } else {
      setTfidfIndex(null);
    }
  }, [products]);

  // Process voice command with confidence and suggestions
  const processCommand = useCallback((text, confidenceScore, alternativesList) => {
    setIsProcessing(true);
    setIsWaitingForMore(false);

    try {
      // Use confidence-aware processing with TF-IDF index
      const commandResult = processVoiceCommandWithConfidence(
        text,
        confidenceScore,
        products,
        customers,
        0.65, // Lower threshold for Vietnamese
        tfidfIndex // Pass TF-IDF index for better matching
      );

      // Get smart suggestions for correction
      const corrections = suggestCorrections(text, products, customers);
      setSuggestions(corrections);

      setResult({
        ...commandResult,
        confidence: confidenceScore,
        alternatives: alternativesList,
        suggestions: corrections
      });
    } catch {
      setResult({
        action: 'error',
        message: 'CÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i.',
      });
    } finally {
      setIsProcessing(false);
      // Reset accumulated transcript sau khi xá»­ lÃ½
      accumulatedTranscriptRef.current = '';
      accumulatedConfidenceRef.current = 0;
      accumulatedAlternativesRef.current = [];
    }
  }, [products, customers, tfidfIndex]);

  // Store latest callback in ref
  useEffect(() => {
    callbackRef.current = (update) => {
      if (update.error) {
        // Ignore "no-speech" error when waiting for more input
        // This happens when recognition restarts but user hasn't spoken yet
        if (update.error === 'no-speech' && accumulatedTranscriptRef.current) {
          // User already said something, just process what we have
          const finalTranscript = accumulatedTranscriptRef.current;
          const finalConfidence = accumulatedConfidenceRef.current;
          const finalAlternatives = accumulatedAlternativesRef.current;

          if (processTimeoutRef.current) {
            clearTimeout(processTimeoutRef.current);
            processTimeoutRef.current = null;
          }

          if (finalTranscript) {
            processCommand(finalTranscript, finalConfidence, finalAlternatives);
          }
          setIsListening(false);
          setIsWaitingForMore(false);
          return;
        }

        // For other errors or no-speech without accumulated transcript
        if (processTimeoutRef.current) {
          clearTimeout(processTimeoutRef.current);
          processTimeoutRef.current = null;
        }

        // Only show notification for real errors, not no-speech during waiting
        if (update.error !== 'no-speech') {
          showNotification(update.message, 'error');
        }

        setIsListening(false);
        setIsWaitingForMore(false);
        accumulatedTranscriptRef.current = '';
        return;
      }

      if (update.ended) {
        // Khi recognition káº¿t thÃºc, náº¿u cÃ³ transcript Ä‘ang chá» thÃ¬ xá»­ lÃ½ luÃ´n
        // (ngÆ°á»i dÃ¹ng Ä‘Ã£ ngá»«ng nÃ³i hoÃ n toÃ n)
        if (accumulatedTranscriptRef.current && processTimeoutRef.current) {
          // Äá»£i thÃªm má»™t chÃºt trÆ°á»›c khi xá»­ lÃ½
          // KhÃ´ng há»§y timeout, Ä‘á»ƒ nÃ³ tá»± cháº¡y
        }
        setIsListening(false);
        return;
      }

      if (update.isFinal) {
        // Há»§y timeout cÅ© náº¿u cÃ³
        if (processTimeoutRef.current) {
          clearTimeout(processTimeoutRef.current);
        }

        // TÃ­ch lÅ©y transcript
        const newTranscript = accumulatedTranscriptRef.current
          ? accumulatedTranscriptRef.current + ' ' + update.transcript
          : update.transcript;

        accumulatedTranscriptRef.current = newTranscript;
        accumulatedConfidenceRef.current = update.confidence;
        accumulatedAlternativesRef.current = update.alternatives || [];

        // Cáº­p nháº­t UI Ä‘á»ƒ hiá»ƒn thá»‹ transcript Ä‘ang chá»
        setTranscript(newTranscript);
        setConfidence(update.confidence);
        setAlternatives(update.alternatives || []);
        setInterimTranscript('');
        setIsWaitingForMore(true);

        // Add to history
        setTranscriptHistory(prev => [...prev, {
          text: update.transcript,
          confidence: update.confidence,
          timestamp: update.timestamp,
          alternatives: update.alternatives
        }]);

        // Äáº·t timeout Ä‘á»ƒ chá» ngÆ°á»i dÃ¹ng nÃ³i thÃªm
        // Náº¿u khÃ´ng cÃ³ thÃªm input trong COMMAND_DELAY_MS, xá»­ lÃ½ lá»‡nh
        processTimeoutRef.current = setTimeout(() => {
          const finalTranscript = accumulatedTranscriptRef.current;
          const finalConfidence = accumulatedConfidenceRef.current;
          const finalAlternatives = accumulatedAlternativesRef.current;

          if (finalTranscript) {
            processCommand(finalTranscript, finalConfidence, finalAlternatives);
          }
          processTimeoutRef.current = null;
          setIsListening(false);
        }, COMMAND_DELAY_MS);

        // Note: Removed auto-restart of recognition to avoid "no-speech" errors
        // User can manually restart by pressing the mic button again if needed
      } else {
        // Interim transcript (while speaking)
        // Hiá»ƒn thá»‹ transcript Ä‘ang tÃ­ch lÅ©y + interim
        const displayTranscript = accumulatedTranscriptRef.current
          ? accumulatedTranscriptRef.current + ' ' + update.transcript
          : update.transcript;
        setInterimTranscript(displayTranscript);
        setConfidence(update.confidence || 0);

        // Há»§y timeout náº¿u ngÆ°á»i dÃ¹ng Ä‘ang nÃ³i tiáº¿p
        if (processTimeoutRef.current) {
          clearTimeout(processTimeoutRef.current);
          processTimeoutRef.current = null;
          setIsWaitingForMore(false);
        }
      }
    };
  }, [processCommand, showNotification]);

  // Initialize enhanced speech recognition ONCE
  useEffect(() => {
    // Wrapper function that always calls the latest callback
    const handleUpdate = (update) => {
      if (callbackRef.current) {
        callbackRef.current(update);
      }
    };

    const recognition = createSpeechRecognition(handleUpdate);

    if (!recognition) {
      setIsSupported(false);
      return;
    }

    recognitionRef.current = recognition;

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      // Cleanup timeout
      if (processTimeoutRef.current) {
        clearTimeout(processTimeoutRef.current);
      }
    };
  }, []); // Empty deps - only create once

  // Start listening
  const startListening = useCallback(() => {
    if (!recognitionRef.current) {
      showNotification('TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ nháº­n diá»‡n giá»ng nÃ³i', 'error');
      return;
    }

    // Há»§y timeout cÅ© náº¿u cÃ³
    if (processTimeoutRef.current) {
      clearTimeout(processTimeoutRef.current);
      processTimeoutRef.current = null;
    }

    // Reset state
    setTranscript('');
    setResult(null);
    setInterimTranscript('');
    setAlternatives([]);
    setSuggestions([]);
    setConfidence(0);
    setIsListening(true);
    setIsWaitingForMore(false);
    accumulatedTranscriptRef.current = '';
    accumulatedConfidenceRef.current = 0;
    accumulatedAlternativesRef.current = [];

    try {
      recognitionRef.current.start();
    } catch {
      // Recognition might already be running
      setIsListening(false);
    }
  }, [showNotification]);

  // Stop listening
  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }

    // Náº¿u cÃ³ transcript Ä‘ang chá», xá»­ lÃ½ ngay
    if (accumulatedTranscriptRef.current && processTimeoutRef.current) {
      clearTimeout(processTimeoutRef.current);
      processTimeoutRef.current = null;

      const finalTranscript = accumulatedTranscriptRef.current;
      const finalConfidence = accumulatedConfidenceRef.current;
      const finalAlternatives = accumulatedAlternativesRef.current;

      processCommand(finalTranscript, finalConfidence, finalAlternatives);
    }

    setIsListening(false);
    setIsWaitingForMore(false);
  }, [processCommand]);

  // Clear result
  const clearResult = useCallback(() => {
    // Há»§y timeout náº¿u cÃ³
    if (processTimeoutRef.current) {
      clearTimeout(processTimeoutRef.current);
      processTimeoutRef.current = null;
    }

    setTranscript('');
    setInterimTranscript('');
    setResult(null);
    setAlternatives([]);
    setSuggestions([]);
    setConfidence(0);
    setIsWaitingForMore(false);
    accumulatedTranscriptRef.current = '';
    accumulatedConfidenceRef.current = 0;
    accumulatedAlternativesRef.current = [];
  }, []);

  // Retry with alternative transcript
  const retryWithAlternative = useCallback((alternativeTranscript) => {
    processCommand(alternativeTranscript, 1.0, []);
  }, [processCommand]);

  // Clear history
  const clearHistory = useCallback(() => {
    setTranscriptHistory([]);
  }, []);

  return {
    isListening,
    isProcessing,
    transcript,
    interimTranscript,
    confidence,
    alternatives,
    result,
    isSupported,
    suggestions,
    transcriptHistory,
    isWaitingForMore, // ThÃªm state má»›i Ä‘á»ƒ UI cÃ³ thá»ƒ hiá»ƒn thá»‹ "Ä‘ang chá»..."
    startListening,
    stopListening,
    clearResult,
    retryWithAlternative,
    clearHistory,
  };
};
